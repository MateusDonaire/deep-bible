import OpenAI from 'openai';
import { PrismaClient } from '@prisma/client';
import * as dotenv from 'dotenv';

dotenv.config();

const prisma = new PrismaClient();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function generateDescriptions() {
  console.log('üìò Iniciando gera√ß√£o de descri√ß√µes para os t√≥picos...');

  const topics = await prisma.topic.findMany({
    where: { description: null },
    orderBy: { id: 'asc' },
  });

  for (const topic of topics) {
    const prompt = `Explique de forma resumida o tema b√≠blico "${topic.name}" para um crist√£o que deseja estudar a B√≠blia de forma mais profunda. Use no m√°ximo 1 frase, em portugu√™s claro, com base no ensino das Escrituras, n√£o cite refer√™ncias b√≠blicas, ex: "Mt 3:5".`;

    try {
      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: prompt }],
        temperature: 0.7,
      });

      const content = response.choices[0].message.content?.trim();

      if (!content) {
        console.warn(`‚ö†Ô∏è Sem resposta para: ${topic.name}`);
        continue;
      }

      await prisma.topic.update({
        where: { id: topic.id },
        data: { description: content },
      });

      console.log(`‚úÖ ${topic.name}: ${content}`);
    } catch (error: any) {
      console.error(`‚ùå Erro no t√≥pico "${topic.name}":`, error.message || error);
    }

  }

  console.log('üéâ Conclu√≠do!');
  await prisma.$disconnect();
}

generateDescriptions();
